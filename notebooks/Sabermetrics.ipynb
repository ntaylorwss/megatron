{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/megatron/work')\n",
    "\n",
    "import megatron\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3e658426ae6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmegatron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/megatron/work/test.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/megatron/pipeline.py\u001b[0m in \u001b[0;36mload_pipeline\u001b[0;34m(filepath, storage_db)\u001b[0m\n\u001b[1;32m    279\u001b[0m     P = Pipeline(stored['inputs'], stored['outputs'], stored['name'],\n\u001b[1;32m    280\u001b[0m                           stored['version'], storage_db)\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstored\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'path'"
     ]
    }
   ],
   "source": [
    "P = megatron.load_pipeline('/home/megatron/work/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example using pandas\n",
    "generator = False\n",
    "lahman_file = 'data/lahman_csv/core/Batting.csv'\n",
    "lahman = pd.read_csv(lahman_file)\n",
    "exclude = ['playerID','yearID','stint','teamID','lgID']\n",
    "\n",
    "if generator:\n",
    "    lahman_generator = megatron.io.generator.PandasGenerator(lahman, 1000,\n",
    "                                                             exclude_cols=exclude)\n",
    "else:\n",
    "    lahman_data = megatron.io.dataset.PandasData(lahman, exclude_cols=exclude)\n",
    "    \n",
    "inputs = megatron.nodes.from_dataframe(lahman, exclude_cols=exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example using csv\n",
    "generator = True\n",
    "lahman_file = 'data/lahman_csv/core/Batting.csv'\n",
    "exclude = ['playerID','yearID','stint','teamID','lgID']\n",
    "\n",
    "if generator:\n",
    "    lahman_generator = megatron.io.generator.CSVGenerator(lahman_file, 1000,\n",
    "                                                          exclude_cols=exclude)\n",
    "else:\n",
    "    lahman_data = megatron.io.dataset.CSVData(lahman_file, exclude_cols=exclude)\n",
    "    \n",
    "inputs = megatron.nodes.from_csv(lahman_file, exclude_cols=exclude, eager=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example using sql database\n",
    "\n",
    "# make sql database from csv\n",
    "lahman_df = pd.read_csv('data/lahman_csv/core/Batting.csv')\n",
    "conn = sqlite3.connect('lahman')\n",
    "conn.execute('DROP TABLE IF EXISTS batting')\n",
    "lahman_df.to_sql('batting', conn, index=False)\n",
    "\n",
    "generator = True\n",
    "conn = sqlite3.connect('lahman')\n",
    "query = 'SELECT * FROM batting'\n",
    "\n",
    "if generator:\n",
    "    lahman_generator = megatron.io.generator.SQLGenerator(conn, query, 1000)\n",
    "else:\n",
    "    lahman_data = megatron.io.dataset.SQLData(conn, query)\n",
    "    \n",
    "inputs = megatron.nodes.from_sql(conn, query, eager=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna = megatron.layers.Impute({np.nan: 0})\n",
    "inputs = fillna(inputs)\n",
    "inputs = megatron.layers.Cast(np.int)(inputs)\n",
    "\n",
    "# helpers\n",
    "def single_fn(h, d, t, hr):\n",
    "    return h - d - t - hr\n",
    "singles = megatron.layers.Lambda(single_fn)(inputs[['H','2B','3B','HR']], 'Singles')\n",
    "hit_types = megatron.layers.Concatenate()([singles]+inputs[['2B','3B','HR']], 'hit_types')\n",
    "TB = megatron.layers.Dot(W=np.array([1,2,3,4]))(hit_types, 'TB')\n",
    "\n",
    "# basics\n",
    "PA = megatron.layers.Add()(inputs[['AB', 'BB', 'HBP', 'SH', 'SF']], 'PA')\n",
    "BBp = megatron.layers.Divide()([inputs['BB'], PA], 'BBpct')\n",
    "Kp = megatron.layers.Divide()([inputs['SO'], PA], 'Kpct')\n",
    "def obp(h, bb, hbp, ab, sf):\n",
    "    return megatron.helpers.safe_divide(h + bb + hbp, ab + bb + hbp + sf)\n",
    "OBP = megatron.layers.Lambda(obp)(inputs[['H','BB','HBP','AB','SF']], 'OBP')\n",
    "SLG = megatron.layers.Divide()([TB, inputs['AB']], 'SLG')\n",
    "AVG = megatron.layers.Divide()(inputs[['H', 'AB']], 'AVG')\n",
    "ISO = megatron.layers.Subtract()([SLG, AVG], 'ISO')\n",
    "def babip(h, hr, ab, k, sf):\n",
    "    return megatron.helpers.safe_divide(h - hr, ab - k - hr + sf)\n",
    "BABIP = megatron.layers.Lambda(babip)(inputs[['H','HR','AB','SO','SF']], 'BABIP')\n",
    "\n",
    "outputs = [PA, BBp, Kp, OBP, SLG, AVG, ISO, BABIP]\n",
    "\n",
    "outputs = megatron.nodes.FeatureSet(outputs)\n",
    "outputs = megatron.layers.Lambda(np.round, decimals=2)(outputs)\n",
    "\n",
    "P = megatron.Pipeline(inputs, outputs, name='test', version=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generator:\n",
    "    P.fit_generator(lahman_generator)\n",
    "    out = P.transform_generator(lahman_generator, cache_result=True)\n",
    "else:\n",
    "    P.fit(lahman_data)\n",
    "    out = P.transform(lahman_data, cache_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.save('/home/megatron/work/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = P.storage.read(lookup=['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AVG': array([0.        , 0.27001953]),\n",
       " 'BABIP': array([0.        , 0.27001953]),\n",
       " 'BBpct': array([0.        , 0.02999878]),\n",
       " 'ISO': array([0.        , 0.04998779]),\n",
       " 'Kpct': array([0., 0.]),\n",
       " 'OBP': array([0.        , 0.30004883]),\n",
       " 'PA': array([  4., 122.]),\n",
       " 'SLG': array([0.        , 0.32006836])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "megatron.visuals.pipeline_imsave(P, 'img/sabermetrics.png')\n",
    "megatron.visuals.pipeline_imshow(P)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
